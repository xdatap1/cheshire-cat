{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hello, dear","text":""},{"location":"#hello-dear","title":"Hello, dear!","text":""},{"location":"#what-is-this","title":"What is this?","text":"<p> The Cheshire Cat is an open-source framework that allows you to develop intelligent agents on top of many Large Language Models (LLM). You can develop your custom AI architecture to assist you in a wide range of tasks.</p> <p>The Cheshire Cat embeds a long-term memory system to save the user's input locally and answer informed by the context of previous conversations. You can also feed text documents in the Cat's memory system to enrich the agent's contextual information and ask it to retrieve them further in the conversation. The Cat currently supports <code>.txt</code>, <code>.pdf</code> and <code>.md</code> files.</p> <p>If you want the Cat to solve tailored tasks you can extend its capabilities writing Python plugins to execute custom functions or call external services (e.g. APIs and other models).</p> <p>If you want to build your custom AI architecture, the Cat can help you!</p> Cheshire Cat Features  Can use external tools  Can ingest documents (.txt, .pdf, .md)  Language model agnostic  Long term memory  Extendible via plugins in Python  100% dockerized"},{"location":"#currently-supported-llms","title":"Currently Supported LLMs","text":"<p>GPT3, ChatGPT, Cohere, HuggingFace Hub, HuggingFace, Azure OpenAI endpoints</p> Get in touch with us!  Discord Join our Discord server and don't forget to give the project a star! \u2b50 Thanks again!\ud83d\ude4f <p></p> <pre><code>\"Would you tell me, please, which way I ought to go from here?\"\n\"That depends a good deal on where you want to get to,\" said the Cat.\n\"I don't much care where--\" said Alice.\n\"Then it doesn't matter which way you go,\" said the Cat.\n\n(Alice's Adventures in Wonderland - Lewis Carroll)\n</code></pre> <p>Credits</p> <p>Logo image generated with MidJourney, prompted by Edgars Romanovskis</p>"},{"location":"advanced/","title":"Advanced","text":""},{"location":"advanced/#advanced","title":"Advanced","text":""},{"location":"advanced/#api-authentication","title":"API Authentication","text":"<p>In order to authenticate endpoints, it is necessary to include the <code>API_KEY=your-key-here</code> variable in the <code>.env</code> file. Multiple keys can be accepted by separating them with a pipe (<code>|</code>) as follows: <code>API_KEY=your-key-here|secondary_client_key</code>.</p> <p>After configuration, all endpoints will require an <code>access_token</code> header for authentication, such as <code>access_token: your-key-here</code>. Failure to provide the correct access token will result in a 403 error.</p> <p>Warning</p> <p>This kind of athentication is weak and it's intended for machine to machine communication, please do not rely on it and enforce other kind of stronger authentication such as OAuth2 for the client side.</p> <p>Example</p> <p>Authenticated API call:</p> PythonNode <pre><code>import requests\nserver_url = 'http://localhost:1865/'\napi_key = 'your-key-here'\naccess_token = {'access_token': api_key}\nresponse = requests.get(server_url, headers=access_token)\nif response.status_code == 200:\nprint(response.text)\nelse:\nprint('Error occurred: {}'.format(response.status_code))\n</code></pre> <pre><code>const request = require('request');\nconst serverUrl = 'http://localhost:1865/';\nconst apiKey = 'your-key-here';\nconst access_token = {'access_token': apiKey};\nrequest({url: serverUrl, headers: access_token}, (error, response, body) =&gt; {\nif (error) {\nconsole.error(error);\n} else {\nif (response.statusCode === 200) {\nconsole.log(body);\n} else {\nconsole.error(`Error occurred: ${response.statusCode}`);\n}\n}\n});\n</code></pre> <p>By adding the variable to the <code>.env</code> file, all Swagger endpoints (<code>localhost:1865/docs</code>) will require authentication and can be accessed on the top right-hand corner of the page through the green Authorize button.   </p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#faq","title":"FAQ","text":""},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#ive-found-the-cat-and-i-like-it-very-much-but-im-not-able-to-follow-your-instructions-to-install-it-on-my-machine-can-you-help","title":"I've found the Cat and I like it very much, but I'm not able to follow your instructions to install it on my machine. Can you help?","text":"<p>The Cheshire Cat is a framework to help developers to build vertical AIs: you will need some basic technical skills to follow our instructions.  Please try to ask in the support channel in our discord server, and remember this is all volunteers effort: be kind! :)</p>"},{"location":"faq/#why-the-cat-does-not-default-to-some-open-llm-instead-of-chatgpt-or-gpt-3","title":"Why the Cat does not default to some open LLM instead of ChatGPT or GPT-3?","text":"<p>Our intention is not to depend on any specific LLM: the Cat does not have a preference about which LLM to use. Nonetheless, at the moment, OpenAI tools still provide the best results for your bucks.  Decision is up to you.</p>"},{"location":"faq/#are-text-and-documents-sent-to-the-cat-safe-and-not-shared-with-anybody","title":"Are text and documents sent to the Cat safe and not shared with anybody?","text":"<p>Well, the local memory is safe and under your control, although embeddings and prompts are shared with your configured LLM, meaning you need to check how safe is the LLM.  We plan to adopt local LLMs, at which point all your data will be under your control.</p>"},{"location":"faq/#basic-info","title":"Basic Info","text":""},{"location":"faq/#can-i-insert-a-long-article-into-the-chat","title":"Can I insert a long article into the chat?","text":"<p>Please avoid pasting long articles into the chat.  Use Rabbit Hole to upload long texts instead: just click on the attachment icon in the chat input widget and upload your file.</p>"},{"location":"faq/#are-the-configured-llm-apis-used-to-instruct-the-cat-with-the-documents-im-going-to-upload","title":"Are the configured LLM APIs used to \"instruct\" the Cat with the documents I'm going to upload?","text":"<p>That's not exactly how it works: basically when you ask something to the Cat, we pass to the configured LLM a prompt with your actual question + data that can be useful to answer that question. Data can be parts of your documents or chat history.  Please check our documentation for more details about how the Cat works for you.</p>"},{"location":"faq/#can-i-talk-to-the-cat-in-a-language-different-from-english","title":"Can I talk to the Cat in a language different from English?","text":"<p>Of course you can: just change the prompts in the Plugin folder accordingly, and take care not to mix languages to get best results.</p>"},{"location":"faq/#how-can-i-know-where-the-cat-gets-the-answers-id-like-to-know-if-its-using-the-files-i-uploaded-or-if-its-querying-the-configured-llm","title":"How can I know where the Cat gets the answers? I'd like to know if it's using the files I uploaded or if it's querying the configured LLM.","text":"<p>Just open the console in your browser to check the logs there. At some point soon, this information will end up in the user interface, but at the moment is behind the scenes.</p>"},{"location":"faq/#i-sent-to-the-cat-some-text-and-documents-i-wont-to-get-rid-of-how-can-i-do","title":"I sent to the Cat some text and documents I won't to get rid of, How can I do?","text":"<p>You can delete the <code>long_term_memory</code> folder and restart the Cat!</p>"},{"location":"faq/#errors","title":"Errors","text":""},{"location":"faq/#why-am-i-getting-the-error-ratelimiterror-in-my-browser-console","title":"Why am I getting the error <code>RateLimitError</code> in my browser console?","text":"<p>Please check if you have a valid credit card connected or if you have used up all the credits of your OpenAI trial period.</p>"},{"location":"faq/#everything-works-in-localhost-but-not-on-another-server","title":"Everything works in localhost but not on another server","text":"<p>You should configure ports in the <code>.env</code> file. Change according to your preferred host and ports: </p><pre><code># Decide host and port for your Cat. Default will be localhost:1865\nCORE_HOST=anotherhost.com\nCORE_PORT=9000\n\n# Decide host and port for your Cat Admin. Default will be localhost:3000\nADMIN_HOST=myhost.eu\nADMIN_PORT=2222\n</code></pre>"},{"location":"faq/#docker-has-no-permissions-to-write","title":"Docker has no permissions to write","text":"<p>This is a matter with your docker installation or the user you run docker from.</p>"},{"location":"faq/#the-cat-seems-not-to-be-working-from-inside-a-virtual-machine","title":"The Cat seems not to be working from inside a Virtual Machine","text":"<p>In VirtualBox you can select Settings-&gt;Network, then choose NAT in the \"Attached to\" drop down menu. Select \"Advanced\" to configure the port forwarding rules. Assuming the guest IP of your VM is 10.0.2.15 (the default) and the ports configred in the .env files are the defaults, you have to set at least the following rules:</p> Rule name Protocol Host IP Host Port Guest IP Guest Port Rule 1 TCP 127.0.0.1 1865 10.0.2.15 1865 Rule 2 TCP 127.0.0.1 3000 10.0.2.15 3000 <p>If you want to work on the documentation of the Cat, you also have to add one rule for port 8000 which is used by <code>mkdocs</code>, and to configure <code>mkdocs</code> itself to respond to all requests (not only localhost as per the default).  </p>"},{"location":"faq/#customization","title":"Customization","text":""},{"location":"faq/#i-want-to-build-my-own-plugin-for-the-cat-what-should-i-know-about-licensing","title":"I want to build my own plugin for the Cat: what should I know about licensing?","text":"<p>Plugins are any license you wish, you can also sell them. The Cat core is GPL3, meaning you are free to fork and go on your own, but you are forced to open source changes to the core.</p>"},{"location":"faq/#port-1865-or-port-3000-are-not-allowed-by-my-operating-system-andor-firewall","title":"Port 1865 or port 3000 are not allowed by my operating system and/or firewall","text":"<p>Change the ports as you wish in the <code>.env</code> file. </p><pre><code># Decide host and port for your Cat. Default will be localhost:1865\nCORE_HOST=localhost\nCORE_PORT=9000\n\n# Decide host and port for your Cat Admin. Default will be localhost:3000\nADMIN_HOST=localhost\nADMIN_PORT=2222\n</code></pre>"},{"location":"features/","title":"Features","text":"<p>TODO</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting started","text":""},{"location":"getting-started/#download","title":"Download","text":"<p>Clone the repository on your machine:</p> <pre><code># Clone the repository\ngit clone https://github.com/pieroit/cheshire-cat.git\n</code></pre>"},{"location":"getting-started/#install","title":"Install","text":"<p>To run the Cheshire Cat, you need to have <code>docker</code> (instructions) and <code>docker-compose</code> (instructions) installed on your system.</p> <ul> <li>Create and API key on the language model provider website  </li> <li>Make a copy of the <code>.env.example</code> file and rename it <code>.env</code></li> <li>Start the app with <code>docker-compose up</code> inside the repository</li> <li>Open the app in your browser at <code>localhost:3000</code></li> <li>Configure a LLM in the <code>Settings</code> tab and paste you API key</li> <li>Start chatting</li> </ul> <p>You can also interact via REST API and try out the endpoints on <code>localhost:1865/docs</code></p> <p>The first time you run the <code>docker-compose up</code> command it will take several minutes as docker images occupy some GBs.</p>"},{"location":"getting-started/#quickstart","title":"Quickstart","text":"<p>Here is an example of a quick setup running the <code>gpt3.5-turbo</code> OpenAI model.  </p> <p>Create an API key with <code>+ Create new secret key</code> in your OpenAI personal account, then:</p>"},{"location":"getting-started/#cli-setup","title":"CLI setup","text":"Linux &amp; MacWindows <pre><code># Open the cloned repository\ncd cheshire-cat\n\n# Create the .env file\ncp .env.example .env\n\n# Run docker containers\ndocker-compose up\n</code></pre> <pre><code># Open the cloned repository\ncd cheshire-cat\n\n# Create the .env file\ncopy .env.example .env\n\n# Run docker containers\ndocker-compose up\n</code></pre>"},{"location":"getting-started/#gui-setup","title":"GUI setup","text":"<p>When you're done using the Cat, remember to CTRL+c in the terminal and <code>docker-compose down</code>.</p>"},{"location":"getting-started/#update","title":"Update","text":"<p>As the project is still a work in progress, if you want to update it run the following: </p><pre><code># Open the cloned repository\ncd cheshire-cat\n\n# Pull from the main remote repository\ngit pull\n\n# Build again the docker containers\ndocker-compose build --no-cache\n\n# Remove dangling images (optional)\ndocker rmi -f $(docker images -f \"dangling=true\" -q)\n# Run docker containers\ndocker-compose up\n</code></pre>"},{"location":"how-the-cat-works/","title":"How the Cat works","text":""},{"location":"how-the-cat-works/#how-the-cat-works","title":"How the Cat works","text":""},{"location":"how-the-cat-works/#components","title":"Components","text":"<p>The Cheshire Cat is made of many pluggable components that make it fully customizable.</p> <code>Chat</code> This is the Graphical User Interface (GUI) component that allows you to interact directly with the Cat.  From the GUI, you can also set the language model you want the Cat to run. <code>Rabbit Hole</code> This component handles the ingestion of documents.  Files that are sent down the Rabbit Hole are split into chunks and saved in the Cat's declarative memory to be further retrieved in the conversation.  <code>Large Language Model (LLM)</code> This is one of the core components of the Cheshire Cat framework.  A LLM is a Deep Learning model that's been trained on a huge volume of text data and can perform many types of language tasks. The model takes a text string as input (e.g. the user's prompt) and provides a meaningful answer.  The answer consistency and adequacy is enriched with the context of previous conversations and documents uploaded in the Cat's memory. <code>Embedder</code> The embedder is another Deep Learning model similar to the LLM. Differently, it doesn't perform language tasks. The model takes a text string as input and encodes it in a numerical representation.  This operation allows to represent textual data as vectors and perform geometrical operation on them. For instance, given an input, the embedder is used to retrieve similar sentences from the Cat's memory. <code>Vector Memory</code> As a result of the Embedder encoding, we get a set of vectors that are used to store the Cat's memory in a vector database. Memories store not only the vector representation of the input, but also the time instant and personalized metadata to facilitate and enhance the information retrieval. The Cat embeds two types of vector memories, namely the episodic and declarative memories.  The formers are the things the human said in the past; the latter the documents sent down the Rabbit hole.  <code>Agent</code> This is another core component of the Cheshire Cat framework.  The agent orchestrates the calls that are made to the LLM.  This component allows the Cat to decide which action to take according to the input the user provides.  Possible actions range from holding the conversation to executing complex tasks, chaining predefined or custom tools. <code>Plugins</code> These are functions to extend the Cat's capabilities.  Plugins are a set of tools and hooks  that allow the Agent to achieve complex goals. This component let the Cat assists you with tailored needs."},{"location":"how-the-cat-works/#main-loop","title":"Main loop","text":""},{"location":"how-the-cat-works/#retrieval-augmented-generation-docs-qa","title":"Retrieval augmented Generation (docs Q&amp;A)","text":""},{"location":"basics/admin-interface/","title":"The Admin Interface","text":""},{"location":"basics/basics/","title":"Folders & APIs","text":""},{"location":"basics/basics/#folders-api","title":"Folders &amp; API","text":"<p>The Cheshire Cat is composed of two main parts: the core functionality resides in the <code>/core</code> folder, and the frontend interface is located in the <code>/admin</code> folder. This document will provide an overview of The Cheshire Cat, including its basic functions and how to access them.</p>"},{"location":"basics/basics/#the-cat-core","title":"The Cat Core","text":"<p>The core functionalities of The Cheshire Cat resides in the <code>/core</code> folder. The core exposes all of its APIs via the address <code>localhost:1865/</code>. The program has several endpoints that can be accessed via this address. All of these endpoints are thoroughly documented and can be easily tested using Swagger (available at <code>localhost:1865/docs</code>) or ReDoc (available at <code>localhost:1865/redoc</code>).</p> <p>Some of these endpoints include:</p> <ul> <li><code>/</code> - This endpoint will return the message <code>\"We're all mad here, dear!\"</code> if the cat is functioning properly.</li> <li><code>/ws/</code> - Use this endpoint to start a chat with the cat using a websocket.</li> <li><code>/rabbithole/</code> - This endpoint allows you to send a file (text, markdown or pdf) to the cat, which will then be saved into its memory. This allows you to share information directly with the cat and for it to access it whenever needed.</li> </ul>"},{"location":"basics/basics/#the-admin-interface","title":"The Admin Interface","text":"<p>The frontend interface of The Cheshire Cat is located in the <code>admin</code> folder and can be accessed via <code>localhost:3000</code>. This interface provides users with an easy-to-use chat that act as playground and can be used to interact with your application.   </p> <p>All the cat's settings are available under this GUI's <code>Settings</code> menu.</p>"},{"location":"basics/cat-core/","title":"The Cat Core","text":""},{"location":"basics/cat-core/#the-cat-core","title":"The Cat Core","text":"<p>The core exposes all of its APIs via the address <code>localhost:1865/</code>.</p> <p>A full documentation with Swagger is inside the Cat itself and can be reached at <code>localhost:1865/docs</code>.</p> Endpoint Method Description / <code>GET</code>  Return the message <code>\"We're all mad here, dear!\"</code> if the cat is running. /ws/ <code>WEBSOCKET</code>  Start a chat with the cat using websockets. /rabbithole/ <code>POST</code>  Send a file (<code>.txt</code>, <code>.md</code> or <code>.pdf</code>) to the cat."},{"location":"basics/cat-core/#interacting-with-the-cat","title":"Interacting with the Cat","text":"<p>Example of how to implement a simple chat system using the websocket endpoint at <code>localhost:1865/ws/</code>.</p> <p>Request JSON schema</p> <p>Sending input will request you to do it in the following specific JSON format <code>{\"text\": \"input message here\"}</code>.</p> <p>Example</p> PythonNode <pre><code>import asyncio\nimport websockets\nimport json\nasync def cat_chat():\ntry:\n# Creating a websocket connection\nasync with websockets.connect('ws://localhost:1865/ws') as websocket:\n# Running a continuous loop until broken\nwhile True:\n# Taking user input and sending it through the websocket\nuser_input = input(\"Human: \")\nawait websocket.send(json.dumps({\"text\": user_input}))\n# Receiving and printing the cat's response\ncat_response = await websocket.recv()\nprint(\"Cheshire Cat:\", cat_response)\nexcept websockets.exceptions.InvalidURI:\nprint(\"Invalid URI provided. Please provide a valid URI.\")\nexcept websockets.exceptions.InvalidStatusCode:\nprint(\"Invalid status code received. Please check your connection.\")\nexcept websockets.exceptions.WebSocketProtocolError:\nprint(\"Websocket protocol error occurred. Please check your connection.\")\nexcept websockets.exceptions.ConnectionClosedOK:\nprint(\"Connection successfully closed.\")\nexcept Exception as e:\nprint(\"An error occurred:\", e)\n# Running the function until completion\nasyncio.get_event_loop().run_until_complete(cat_chat())\n</code></pre> <pre><code>const WebSocket = require('ws');\nasync function cat_chat() {\ntry {\nconst socket = new WebSocket('ws://localhost:1865/ws/');\n//Listen for connection event and log a message\nsocket.on('open', () =&gt; {\nconsole.log('Connected to the Ceshire Cat');\n});\n//Listen for message event and log the received data message\nsocket.on('message', (data) =&gt; {\nconsole.log(`Cheshire Cat: ${data}`);\n});\n//Iterate indefinitely while waiting for user input\nwhile (true) {\n//Call getUserInput function and wait for user input\nconst user_input = await getUserInput('Human: ');\nsocket.send(user_input);\n}\n} catch (error) {\nconsole.error(error);\n}\n}\n//Define a function named getUserInput that returns a Promise\nfunction getUserInput(prompt) {\nreturn new Promise((resolve) =&gt; {\nconst stdin = process.openStdin();\nprocess.stdout.write(prompt);\n//Listen for data input events and resolve the Promise with the input\nstdin.addListener('data', (data) =&gt; {\nresolve(data.toString().trim());\nstdin.removeAllListeners('data');\n});\n});\n}\n//Call the cat_chat function\ncat_chat();\n</code></pre>"},{"location":"basics/cat-core/#interacting-with-rabbithole","title":"Interacting with Rabbithole","text":"<p>Example of how to send a text file (<code>.md</code>,<code>.pdf.</code>,<code>.txt</code>) to the Cat using the Rabbit Hole at <code>localhost:1865/rabbithole/</code>.</p> <p>Currently the following MIME types are supported: * <code>text/plain</code> * <code>text/markdown</code> * <code>application/pdf</code></p> <p>Example</p> PythonNodecURL <pre><code>import requests\nurl = 'http://localhost:1865/rabbithole/'\nwith open('alice.txt', 'rb') as f:\nfiles = {\n'file': ('alice.txt', f, 'text/plain')\n}\nheaders = {\n'accept': 'application/json',\n}\nresponse = requests.post(url, headers=headers, files=files)\nprint(response.text)\n</code></pre> <pre><code>const request = require('request');\nconst fs = require('fs');\nconst url = 'http://localhost:1865/rabbithole/';\nconst file = fs.createReadStream('alice.txt');\nconst formData = {\nfile: {\nvalue: file,\noptions: {\nfilename: 'alice.txt',\ncontentType: 'text/plain'\n}\n}\n};\nconst options = {\nurl: url,\nheaders: {\n'accept': 'application/json'\n},\nformData: formData\n};\nrequest.post(options, function(err, res, body) {\nif (err) {\nreturn console.error('Error:', err);\n}\nconsole.log('Body:', body);\n});\n</code></pre> <pre><code># Upload an ASCII text file\ncurl -v -X POST -H \"accept: application/json\" -F \"file=@file.txt;type=text/plain\" http://127.0.0.1:1865/rabbithole/\n\n# Upload a Markdown file\ncurl -v -X POST -H \"accept: application/json\" -F \"file=@file.md;type=text/markdown\" http://127.0.0.1:1865/rabbithole/\n\n# Upload a PDF file\ncurl -v -X POST -H \"accept: application/json\" -F \"file=@myfile.pdf;type=application/pdf\" http://127.0.0.1:1865/rabbithole/\n</code></pre>"},{"location":"plugins/hooks/","title":"Hooks","text":""},{"location":"plugins/hooks/#hooks","title":"Hooks","text":""},{"location":"plugins/hooks/#todo-insert-hook-search","title":"TODO: insert hook search","text":""},{"location":"plugins/plugins/","title":"How to write a plugin","text":""},{"location":"plugins/plugins/#how-to-write-a-plugin","title":"How to write a plugin","text":"<p>To write a plugin just create a new folder in <code>core/cat/plugins/</code>. </p> <p>Add a python file to your plugin folder:</p> <pre><code>\u251c\u2500\u2500 core\n\u2502   \u251c\u2500\u2500 cat\n\u2502   \u2502   \u251c\u2500\u2500 plugins\n|   |   |   \u251c\u2500\u2500 myplugin\n|   |   |   |   \u251c mypluginfile.py\n</code></pre> <p>Now let's start <code>mypluginfile.py</code> with a little import:</p> <pre><code>from cat.mad_hatter.decorators import tool, hook\n</code></pre> <p>You are now ready to change the Cat's behavior using Tools and Hooks.</p>"},{"location":"plugins/plugins/#tools","title":"Tools","text":"<p>Tools are python functions that can be selected from the language model (LLM). Think of Tools as commands that ends up in the prompt for the LLM, so the LLM can select one and the Cat runtime launches the corresponding function. Here is an example of Tool to let the Cat tell you what time it is:</p> <pre><code>@tool\ndef get_the_time(tool_input, cat):\n\"\"\"Retrieves current time and clock. Input is always None.\"\"\"\nreturn str(datetime.now())\n</code></pre> <p>More examples on tools here</p>"},{"location":"plugins/plugins/#hooks","title":"Hooks","text":"<p>Hooks are also python functions, but they pertain the Cat's runtime and not striclty the LLM. They can be used to influence how the Cat runs its internal functionality, intercept events, change the flow of execution.  </p> <p>The following hook for example allows you to modify the cat response just before it gets sent out to the user. In this case we make a \"grumpy rephrase\" of the original response.</p> <pre><code>@hook\ndef before_cat_sends_message(message, cat):\nprompt = f'Rephrase the following sentence in a grumpy way: {message[\"content\"]}'\nmessage[\"content\"] = cat.llm(prompt)\nreturn message\n</code></pre> <p>More examples on hooks here</p>"},{"location":"plugins/tools/","title":"Tools","text":""},{"location":"plugins/tools/#tools","title":"Tools","text":"<p>A Tool allows the Cat to execute custom code during conversation, for example:</p> <ul> <li>communicate with a web service</li> <li>search information in an external database</li> <li>execute math calculations</li> <li>run stuff in the terminal (danger zone)</li> <li>keep track of specific information and do fancy stuff with it</li> <li>your fantasy is the limit!</li> </ul> <p>Tools in the Cheshire Cat are inspired and extend langchain Tools, an elegant Toolformer implementation.</p>"},{"location":"plugins/tools/#your-first-tool","title":"Your first Tool","text":"<p>A Tool is just a python function. In your <code>mypluginfile.py</code> create a new function with the <code>@tool</code> decorator:</p> <pre><code>@tool # (1)\ndef get_the_time(tool_input, cat): # (2)\n\"\"\"Retrieves current time and clock. Input is always None.\"\"\" # (3)\nreturn str(datetime.now()) # (4)\n</code></pre> <ol> <li>Python functions in a plugin only become tools if you use the <code>@tool</code> decorator</li> <li>Every <code>@tool</code> receives two arguments: a string representing the tool input, and the Cat instance. </li> <li>This doc string is necessary, as it will show up in the LLM prompt. It should describe what the tool is useful for and how to prepare inputs, so the LLM can select the tool and input it properly.</li> <li>Always return a string, which goes back to the prompt informing the LLM on the Tool's output.</li> </ol> <p>Let's see all the parts step by step...</p> <p>TODO:</p> <ul> <li>a better example?</li> <li>show how tools are displayed in the prompt and how the LLM selects them</li> <li>more examples with little variations<ul> <li>the tool calls an external service</li> <li>the tool reads/writes a file</li> <li>the input string contains a dictionary (to be parsed with <code>json.loads</code>)</li> <li>the tool manages a conversational form</li> <li><code>@tool(return_direct=True)</code> to let the returned string go straight to the chat</li> <li>show how you can access cat's functionality (memory, llm, embedder, rabbit_hole) from inside a tool</li> <li>what else? dunno</li> </ul> </li> </ul>"},{"location":"tutorials/installation-customization/","title":"Installation and customization","text":""},{"location":"tutorials/installation-customization/#installation-customization","title":"Installation &amp; Customization","text":"<p>Watch it on YouTube</p>"},{"location":"tutorials/overview/","title":"Overview","text":""},{"location":"tutorials/overview/#overview","title":"Overview","text":"<p>Watch it on YouTube</p>"}]}